---
phase: 02-interval-optimization
plan: 03
type: execute
---

<objective>
Test 50ms extreme interval for maximum possible congestion response while maintaining stability.

Purpose: Explore absolute performance limit of the control system. This is 20x faster than original (1s → 50ms) and represents the theoretical limit before measurement latency (30-40ms) approaches cycle time.
Output: 50ms interval tested, stability assessment complete, production configuration finalized at optimal interval (50ms/100ms/250ms).
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@docs/FASTER_RESPONSE_INTERVAL.md
@docs/INTERVAL_TESTING_250MS.md
@docs/INTERVAL_TESTING_100MS.md
@.planning/phases/02-interval-optimization/02-01-SUMMARY.md
@.planning/phases/02-interval-optimization/02-02-SUMMARY.md
@src/wanctl/autorate_continuous.py
@configs/spectrum.yaml
@configs/att.yaml
@configs/steering_config_v2.yaml

**Prerequisites:**
- Plan 02-02 complete with decision to test 50ms
- 100ms interval proven stable

**Current state (after 02-02):**
- Cycle interval: 100ms
- Cycle execution: 30-40ms
- Margin: 60-70ms per cycle

**Challenge with 50ms:**
- Cycle execution: 30-40ms
- Interval: 50ms
- Margin: Only 10-20ms (tight!)
- Risk: Cycle execution time variance could approach interval time
- Consequence: Cycles might overlap if execution occasionally spikes to 45-50ms

**Target for 50ms:**
- Congestion detection: 80 samples × 50ms = 4 seconds
- Recovery: 600 samples × 50ms = 30 seconds
- Expected CPU: ~40-50% (20 REST calls/second)
- Network: 60 pings/second (high but sustainable)

**This is an EXTREME test:** 50ms may be the physical limit given 30-40ms execution time.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Calculate and apply 50ms extreme interval parameters</name>
  <files>src/wanctl/autorate_continuous.py, configs/spectrum.yaml, configs/att.yaml, configs/steering_config_v2.yaml, src/wanctl/steering/daemon.py</files>
  <action>
Update cycle interval and all dependent parameters for 50ms extreme operation:

1. **Autorate interval:** CYCLE_INTERVAL_SECONDS = 0.05 (from 0.1)

2. **EWMA alphas (VERY aggressive smoothing - 2x reduction from 100ms):**
   - Spectrum: alpha_baseline: 0.0005 (from 0.001), alpha_load: 0.005 (from 0.01)
   - ATT: alpha_baseline: 0.000375 (from 0.00075), alpha_load: 0.005 (from 0.01)

3. **Steering thresholds (2x sample counts from 100ms):**
   - interval_seconds: 0.05 (from 0.1)
   - red_samples_required: 80 (from 40) - maintains 4 second activation
   - green_samples_required: 600 (from 300) - maintains 30 second recovery
   - history_size: 2400 (from 1200) - maintains 2 minute history

4. **Steering daemon MAX_HISTORY_SAMPLES:** 2400 (from 1200)

**Mathematical verification:**
- Baseline smoothing: 2000 samples × 0.05s = 100 seconds (preserved)
- Load smoothing: 200 samples × 0.05s = 10 seconds (preserved)
- RED activation: 80 × 0.05s = 4 seconds (preserved)
- GREEN recovery: 600 × 0.05s = 30 seconds (preserved)

**CRITICAL - Extreme smoothing required:**
At 50ms (20 Hz sampling), alpha_baseline=0.0005 means each sample contributes only 0.05% to average. This is EXTREMELY conservative but necessary to prevent noise from causing chaos at this aggressive rate.

alpha_load=0.005 (0.5% per sample) is also very conservative - load changes will be heavily smoothed over 200 samples (10 seconds). This is intentional to prevent flapping.

**Physical constraint awareness:**
- Cycle execution: 30-40ms
- Interval: 50ms
- If execution occasionally spikes to 45-50ms, cycles could overlap or delay
- The event loop should handle this gracefully (skip cycles if behind), but it's a risk

**What to avoid:** Do NOT reduce smoothing to "respond faster" - at 20 Hz, any less smoothing will cause severe instability. The fast interval provides responsiveness; smoothing provides stability.
  </action>
  <verify>
1. `python3 -m py_compile src/wanctl/autorate_continuous.py` passes
2. `python3 -m py_compile src/wanctl/steering/daemon.py` passes
3. Config files are valid YAML
4. Alpha values: alpha_baseline ≤ 0.0005, alpha_load = 0.005
5. Sample counts: red=80, green=600, history=2400
6. History size 2400 is reasonable for memory (not excessive)
  </verify>
  <done>
- Interval set to 0.05 (50ms)
- EWMA alphas extremely conservative (0.0005/0.005)
- Steering thresholds doubled from 100ms
- History sizes doubled (2400 samples = 2 minutes at 50ms)
- Ready for extreme interval testing
  </done>
</task>

<task type="auto">
  <name>Task 2: Deploy 50ms configuration with careful initial monitoring</name>
  <files>Deployment via systemd</files>
  <action>
Deploy 50ms configuration with heightened caution:

1. Deploy to ONE WAN first (ATT recommended - simpler 3-state logic):
   - Copy configs and code to cake-att only
   - Restart wanctl@att service
   - Monitor for 30-60 minutes

2. Check for immediate red flags:
   - Cycle timing variance: are cycles completing in <50ms consistently?
   - `journalctl -u wanctl@att -f | grep cycle`
   - Look for: "cycle took XXms" - should be 30-45ms, not 50ms+
   - If cycles approach 50ms: event loop is struggling, abort test

3. If ATT stable for 1 hour, deploy to Spectrum:
   - Spectrum has 4-state logic (more complex) so test ATT first
   - Copy configs and code to cake-spectrum
   - Restart wanctl@spectrum and wanctl-steering

4. Monitor both WANs for 2-3 hours before declaring initial stability

**Abort criteria (immediate rollback to 100ms):**
- Cycle execution time exceeds 45ms regularly
- Services crash or hang
- Router CPU >60%
- Severe flapping in first 10 minutes
- Any indication of cycle overlap or timing violations

**What to avoid:** Do NOT deploy to both WANs simultaneously - staged rollout reduces risk.
  </action>
  <verify>
1. ATT stable for 1+ hour before Spectrum deployment
2. Cycle execution times: 30-45ms (under 50ms threshold)
3. No crashes or hangs
4. Router CPU <60%
5. No severe flapping
6. Event loop timing healthy (no overlap/skip messages)
  </verify>
  <done>
- 50ms deployed to ATT, validated stable
- 50ms deployed to Spectrum, initial stability confirmed
- Cycle timing within acceptable range
- Ready for extended monitoring
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>50ms extreme interval deployed to production</what-built>
  <how-to-verify>
Monitor for 24-48 hours with focus on extreme interval challenges:

1. **Cycle execution timing (CRITICAL at 50ms):**
   - `ssh cake-spectrum 'journalctl -u wanctl@spectrum --since "24 hours ago" | grep "cycle took" | tail -100'`
   - Confirm: 95%+ of cycles complete in <45ms
   - Red flag: Cycles approaching 50ms (approaching interval limit)
   - If cycles regularly take 48-50ms: system is at physical limit, unstable

2. **Event loop health:**
   - Check for "skipped cycle" or "cycle overlap" messages
   - Event loop should maintain 50ms cadence without skipping
   - If cycles are being skipped: execution time too close to interval

3. **Baseline RTT stability (HARDEST at 50ms):**
   - 20 Hz sampling amplifies noise 20x vs original
   - `ssh cake-spectrum 'journalctl -u wanctl@spectrum --since "24 hours ago" | grep baseline | tail -200'`
   - Confirm: Baseline still stable despite extreme sampling rate
   - Look for: EWMA smoothing (alpha=0.0005) preventing noise from causing drift

4. **No flapping from extreme sampling rate:**
   - `ssh cake-spectrum 'journalctl -u wanctl@spectrum --since "6 hours ago" | grep download_rate | tail -100'`
   - At 20 Hz, small RTT jitter could trigger rapid state changes
   - Confirm: Rate changes are smooth, correlate with real congestion
   - Pattern: No rapid up/down/up/down sequences

5. **Router infrastructure strain:**
   - 20 REST API calls/second = 1200/minute to router
   - Check router: `/system resource print`
   - CPU should be <60%, memory stable
   - If router struggles: 50ms exceeds hardware capacity

6. **Network measurement sustainability:**
   - 60 ICMP pings/second to reflectors (1.1.1.1, 8.8.8.8, 9.9.9.9)
   - Check for: Increased ping loss, timeout increases
   - Reflectors might rate-limit at this volume

7. **State transition quality:**
   - `ssh cake-spectrum 'journalctl -u wanctl-steering --since "24 hours ago" | grep -E "RED|YELLOW" | head -30'`
   - 80 samples for RED = 4 seconds (same time-constant, tighter threshold)
   - Verify: Transitions still correlate with congestion, not noise

8. **Practical benefit assessment:**
   - Is 50ms measurably better than 100ms?
   - Congestion detection: 50ms × 80 = 4s (same as 100ms × 40)
   - Recovery: 50ms × 600 = 30s (same as 100ms × 300)
   - Question: Is 50ms providing benefit, or just risk?

9. **Compare to 100ms baseline:**
   - Stability: 50ms vs 100ms
   - Resource usage: 50ms vs 100ms
   - Practical performance: Is there measurable improvement?
  </how-to-verify>
  <resume-signal>
Type one of:
- "approved-50ms" - 50ms stable, finalize at 50ms (extreme performance)
- "finalize-100ms" - 50ms works but too aggressive, finalize at 100ms (safe performance)
- "finalize-250ms" - 100ms/50ms both too aggressive, finalize at 250ms (conservative)
- "issues: [description]" - instability found
- "rollback" - 50ms unstable, revert to 100ms
  </resume-signal>
</task>

<task type="auto">
  <name>Task 3: Finalize production configuration at optimal interval</name>
  <files>configs/spectrum.yaml, configs/att.yaml, configs/steering_config_v2.yaml, src/wanctl/autorate_continuous.py, src/wanctl/steering/daemon.py, docs/INTERVAL_OPTIMIZATION_FINAL.md</files>
  <action>
Based on testing results, finalize at the optimal interval:

1. **If finalizing at 50ms (approved-50ms):**
   - Current configuration is optimal, no changes
   - Document: "Finalized at 50ms - maximum performance achieved"

2. **If finalizing at 100ms (finalize-100ms or rollback from 50ms):**
   - Revert to 100ms parameters from 02-02
   - Deploy to both WANs
   - Document: "Finalized at 100ms - optimal balance of performance and stability"

3. **If finalizing at 250ms (finalize-250ms):**
   - Revert to 250ms parameters from 02-01
   - Deploy to both WANs
   - Document: "Finalized at 250ms - conservative stable performance"

4. **Create final documentation (docs/INTERVAL_OPTIMIZATION_FINAL.md):**
   - Summary of all intervals tested (500ms → 250ms → 100ms → 50ms)
   - Stability results for each
   - Final decision and rationale
   - Production parameters (interval, alphas, thresholds)
   - Performance achieved:
     * Congestion detection time: [X] seconds
     * Recovery time: [Y] seconds
     * CPU utilization: [Z]%
     * Improvement over original (2s interval): [N]x faster

5. **Update CLAUDE.md if needed:**
   - Document final interval if different from 500ms
   - Note any architectural insights from testing

**What to avoid:** Don't finalize at an unstable interval just to claim maximum performance. Stability is more important than speed.
  </action>
  <verify>
1. Production running at optimal interval
2. Configuration files reflect final parameters
3. docs/INTERVAL_OPTIMIZATION_FINAL.md exists with complete analysis
4. CLAUDE.md updated if configuration changed
5. All services stable under final configuration
  </verify>
  <done>
- Production finalized at optimal interval: [50ms/100ms/250ms]
- Complete testing documentation created
- Rationale for final choice documented
- Phase 2 objectives achieved
  </done>
</task>

<task type="auto">
  <name>Task 4: Document 50ms test results and final recommendation</name>
  <files>docs/INTERVAL_TESTING_50MS.md</files>
  <action>
Create final analysis document for 50ms testing:

**Structure:**
1. **Test Parameters:** 50ms interval, extreme EWMA values (0.0005/0.005), thresholds (80/600)
2. **Physical Limits Analysis:**
   - Cycle execution time: [distribution, max observed]
   - Interval headroom: 50ms - execution time
   - Did we hit physical limits? (execution time approaching interval)
3. **Stability Assessment:**
   - Baseline RTT at 20 Hz sampling
   - Flapping incidents
   - Router infrastructure strain (CPU, API responsiveness)
   - Network measurement sustainability (ping loss, reflector responses)
4. **Performance Comparison Table:**
   | Interval | Detection | Recovery | CPU | Stability | Notes |
   |----------|-----------|----------|-----|-----------|-------|
   | 500ms | 4s | 30s | ~10% | Stable | Baseline from Phase 1 |
   | 250ms | 4s | 30s | ~20% | [result] | First test |
   | 100ms | 4s | 30s | ~30% | [result] | Aggressive |
   | 50ms | 4s | 30s | ~50% | [result] | Extreme |

5. **Final Recommendation:**
   - Optimal interval: [50ms/100ms/250ms]
   - Why: [stability, performance, resource usage trade-offs]
   - What we learned about system limits

**Key insight:** Time constants are preserved across all intervals (4s detection, 30s recovery). The choice is about stability vs resource usage, not performance.
  </action>
  <verify>
1. Document exists at docs/INTERVAL_TESTING_50MS.md
2. Physical limits analysis included
3. Complete comparison table
4. Clear final recommendation with rationale
5. System limits documented
  </verify>
  <done>
- 50ms test results documented
- Physical limits explored and documented
- Final interval recommendation provided
- Phase 2 complete
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] 50ms parameters calculated (extreme EWMA smoothing)
- [ ] 50ms deployed and monitored for 24-48h
- [ ] Cycle timing validated (execution <45ms consistently)
- [ ] Physical limits assessed (did we hit them?)
- [ ] Stability vs. 100ms baseline evaluated
- [ ] Production finalized at optimal interval
- [ ] Complete documentation (50ms test + final recommendation)
</verification>

<success_criteria>
- 50ms interval tested to completion
- Physical system limits explored
- Production finalized at optimal interval (50ms/100ms/250ms based on testing)
- Complete documentation of all interval testing
- Final configuration stable and documented
- Phase 2 objectives achieved: fastest stable interval determined
</success_criteria>

<output>
After completion, create `.planning/phases/02-interval-optimization/02-03-SUMMARY.md`:

# Phase 2 Plan 3: 50ms Extreme Interval Testing Summary

**Explored absolute performance limits, production finalized at [50ms/100ms/250ms]**

## Accomplishments

- Tested 50ms extreme interval (20x faster than original)
- Explored physical limits (cycle execution vs interval timing)
- Validated stability at [50ms/rollback to 100ms/rollback to 250ms]
- Finalized production configuration at optimal interval
- Documented complete interval testing series (250ms → 100ms → 50ms)

## Files Created/Modified

- `src/wanctl/autorate_continuous.py` - Final interval: [value]
- `configs/spectrum.yaml` - Final EWMA alphas: [values]
- `configs/att.yaml` - Final EWMA alphas: [values]
- `configs/steering_config_v2.yaml` - Final thresholds: [values]
- `src/wanctl/steering/daemon.py` - Final history: [value]
- `docs/INTERVAL_TESTING_50MS.md` - 50ms test analysis
- `docs/INTERVAL_OPTIMIZATION_FINAL.md` - Final recommendation and production config

## Decisions Made

- Final interval: [50ms/100ms/250ms]
- Rationale: [stability, performance, physical limits, resource usage]
- 50ms result: [Stable at limit / Exceeded physical limits / Unstable]
- Phase 2 complete: Fastest stable interval determined

## Issues Encountered

[50ms challenges: cycle timing, flapping, router strain, or "None - 50ms stable"]

## Physical Limits Discovered

- Cycle execution: [30-45ms range]
- Optimal interval: [50ms/100ms/250ms] based on [execution time margin / stability / router capacity]
- System can sustain: [X] REST calls/second, [Y] pings/second

## Next Step

**Phase 2 Complete - Interval optimization finalized**

Production running at [X]ms interval - [N]x faster congestion response than original 2s baseline.

Ready for Phase 3 or milestone completion.
</output>
