---
phase: 01-measurement-infrastructure-profiling
plan: 02
type: execute
---

<objective>
Collect baseline profiling data from production cycles and analyze latency breakdown to identify bottleneck sources.

Purpose: Generate concrete latency statistics (min/max/avg/p95/p99) for each measurement subsystem so Phase 2+ optimization work can target highest-impact areas.

Output: Profiling analysis report showing latency distribution across RouterOS, ICMP, CAKE subsystems
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-measurement-infrastructure-profiling/01-01-SUMMARY.md
@src/wanctl/perf_profiler.py (created in 01-01)
@src/wanctl/steering/daemon.py (instrumented in 01-01)
@src/wanctl/autorate_continuous.py (instrumented in 01-01)

**Previous Plan Summary:**
- Plan 01-01 created perf_profiler.py module and integrated timing hooks
- Measurement cycles now log individual subsystem latencies
- Foundation ready for data collection phase

**Profiling Strategy:**
- Collect data over 7-14 day period (typical operation includes various network conditions)
- Gather statistics from both steering (2-second cycles) and autorate (default 10-minute cycles)
- Analyze percentiles (p95, p99) to identify occasional spikes
- Compare REST API vs SSH transport latencies if both in use
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create data collection and analysis script</name>
  <files>scripts/analyze_profiling.py, scripts/profiling_collector.py</files>
  <action>
Create two helper scripts for profiling data collection and analysis:

**scripts/profiling_collector.py** - Log parser and aggregator:
- Command-line tool to parse wanctl logs and extract profiling data
- Usage: `python scripts/profiling_collector.py /var/log/wanctl/wan1.log --subsystem steering_rtt_measurement`
- Reads logs, extracts timing lines (matches pattern: "label: X.Xms")
- Collects measurements for specified subsystem (or --all for all subsystems)
- Outputs JSON with statistics: {subsystem: {count, min_ms, max_ms, avg_ms, p95_ms, p99_ms, samples: [...]}}
- Options:
  - `--log-file PATH` - Log file to parse (required)
  - `--subsystem NAME` - Filter to specific subsystem (optional, default: all)
  - `--output FORMAT` - Output as json, csv, or text (default: text)
  - `--time-window HOURS` - Analyze last N hours (default: all)
  - `--percentiles P1,P2,P3` - Calculate specific percentiles (default: 95,99)

**scripts/analyze_profiling.py** - Analysis and report generator:
- Aggregates multiple log files into single analysis report
- Usage: `python scripts/analyze_profiling.py --config configs/wan1.yaml --days 7`
- Generates markdown report showing:
  - Summary statistics (mean, min, max, p95, p99 for each subsystem)
  - Bottleneck identification (which subsystem takes most time: RouterOS, ICMP, CAKE)
  - Comparison table: subsystem vs time spent vs percentage of cycle
  - Recommendations (e.g., "ICMP ping takes 40% of cycle - prioritize reduction")
  - Time series (optional: --time-series to show latency over collection period)
- Output: Markdown report written to stdout or --output FILE
- Reads from configured log path in config YAML

**Implementation notes:**
- Use regex to extract timing lines: `(\w+): (\d+\.\d+)ms`
- Store samples in lists for percentile calculation
- Use statistics.quantiles() or numpy if available (fallback to manual sort+index)
- Handle missing data gracefully (N/A for unavailable subsystems)
- No external dependencies beyond Python stdlib (requests/paramiko not needed for analysis)

**Files created:** 2
**Approximate lines:** 150 lines per script
  </action>
  <verify>
python scripts/profiling_collector.py --help | grep -q "usage"
python scripts/analyze_profiling.py --help | grep -q "usage"
python scripts/profiling_collector.py /var/log/wanctl/wan1.log --subsystem steering_rtt_measurement 2>&1 | head -5
  </verify>
  <done>
Both scripts have help output, profiling_collector runs without errors on real logs, analysis script generates markdown report
  </done>
</task>

<task type="auto">
  <name>Task 2: Document profiling procedure and baseline expectations</name>
  <files>docs/PROFILING.md</files>
  <action>
Create documentation guide for collecting and analyzing profiling data:

**docs/PROFILING.md** should include:

1. **Overview** - What profiling measures and why it matters for optimization
2. **Prerequisites** - Instructions to verify Plan 01-01 instrumentation is deployed
3. **Data Collection Procedure:**
   - How long to collect (minimum 7 days recommended, 2-4 weeks ideal)
   - Why duration matters (captures various network conditions)
   - How to monitor collection (grep logs for timing output)
   - Multiple transport testing (if possible, test with REST and SSH separately)

4. **Expected Baseline** (from PROJECT.md):
   - RouterOS SSH: ~150ms per command
   - ICMP ping (3 samples): ~100-150ms total
   - CAKE stats read: ~50-100ms per query
   - Approximate cycle totals:
     - Steering (2s cycles): ~200-250ms overhead, leaves 1.8s for decision making
     - Autorate (10m cycles): Time not critical (runs every 10 minutes)

5. **Analysis Steps:**
   ```bash
   # Step 1: Collect data from production logs
   cp /var/log/wanctl/wan1.log profiling_data/wan1_baseline.log

   # Step 2: Extract profiling statistics
   python scripts/profiling_collector.py profiling_data/wan1_baseline.log --all

   # Step 3: Generate analysis report
   python scripts/analyze_profiling.py --config configs/wan1.yaml --output reports/wan1_baseline.md

   # Step 4: Review report for bottleneck identification
   cat reports/wan1_baseline.md
   ```

6. **Interpreting Results:**
   - Which subsystem dominates total time?
   - Are there spikes (p99 >> avg)?
   - Does one transport (REST vs SSH) outperform other?
   - Is cycle time consistently < 2 seconds (steering)?

7. **Next Steps:**
   - Use findings to prioritize Phase 2-4 optimization work
   - Phases targeting highest-latency subsystems first
   - Re-collect data after each optimization to measure improvement

**Files created:** 1
**Approximate lines:** 100-120
  </action>
  <verify>
test -f docs/PROFILING.md && wc -l docs/PROFILING.md
grep -q "Expected Baseline\|Data Collection\|Analysis Steps" docs/PROFILING.md
  </verify>
  <done>
Documentation file created, contains procedure sections and baseline expectations, grep finds all expected sections
  </done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `python scripts/profiling_collector.py --help` - Help output shows all options
- [ ] `python scripts/analyze_profiling.py --help` - Help output shows all options
- [ ] `python -m py_compile scripts/*.py` - No syntax errors in scripts
- [ ] Test scripts on sample log data (create minimal test log if real logs unavailable)
- [ ] `docs/PROFILING.md` exists and has expected sections (grep for headings)
- [ ] All Phase 1 instrumentation still working (logs show timing output)
</verification>

<success_criteria>

- Profiling collection script created and runnable
- Analysis script creates markdown report output
- Documentation guide written with clear procedures
- All scripts handle errors gracefully (no unhandled exceptions)
- Ready for production data collection
  </success_criteria>

<output>
After completion, create `.planning/phases/01-measurement-infrastructure-profiling/01-02-SUMMARY.md`:

# Phase 1 Plan 2 Summary: Profiling Data Collection Infrastructure

**Created analysis tools and documentation for systematic baseline profiling collection.**

## Accomplishments

- Created profiling_collector.py for extracting timing data from logs
- Created analyze_profiling.py for aggregating profiling statistics across time
- Wrote comprehensive PROFILING.md documentation guide
- Documented baseline expectations and analysis procedures

## Files Created/Modified

- `scripts/profiling_collector.py` - Log parser for extracting subsystem timings
- `scripts/analyze_profiling.py` - Report generator for profiling analysis
- `docs/PROFILING.md` - Data collection and analysis procedures

## Decisions Made

- Used regex for log parsing (simple, no external deps, maintainable)
- Deferred time-series visualization to future phase (markdown reports sufficient for initial analysis)
- Documented 7-14 day collection window (balances reasonable data volume with multiple network conditions)
- Analysis in markdown format for easy sharing and version control

## Issues Encountered

None - implementation straightforward, data extraction from existing log format

## Next Step

Phase 1 complete: Ready for Phase 2 RouterOS Communication Optimization
Execute profiling data collection over 7-14 days, then run analysis to identify prioritized optimization targets.
</output>
